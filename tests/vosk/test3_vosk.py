import json
import os
import wave
import time
import threading
import tempfile
import numpy as np
import pyaudio
from collections import deque
from datetime import datetime
from vosk import Model, KaldiRecognizer

# ğŸ”§ Parametry zvuku
RATE = 16000
CHUNK = 1024
CHANNELS = 1

# ğŸ”Š VAD parametry
SILENCE_THRESHOLD = 200      # PrÃ¡h pro detekci ticha (experimentujte s hodnotami 200-2000)
MIN_SPEECH_DURATION = 0.5    # MinimÃ¡lnÃ­ dÃ©lka Å™eÄi v sekundÃ¡ch pro zahÃ¡jenÃ­ nahrÃ¡vÃ¡nÃ­
SILENCE_DURATION = 1.5       # DÃ©lka ticha v sekundÃ¡ch pro ukonÄenÃ­ vÄ›ty
MAX_RECORDING_TIME = 30      # MaximÃ¡lnÃ­ dÃ©lka nahrÃ¡vÃ¡nÃ­ v sekundÃ¡ch

# ğŸ“ SloÅ¾ka pro uloÅ¾enÃ­ nahrÃ¡vek a pÅ™episÅ¯
OUTPUT_DIR = "recordings"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ğŸ¤– Vosk model - upravte cestu podle vaÅ¡Ã­ instalace
MODEL_PATH = "/Users/jakubvavra/Desktop/Automoitoring/tests/vosk/vosk-model-small-cs-0.4-rhasspy"

def list_audio_devices():
    """VypÃ­Å¡e seznam dostupnÃ½ch audio zaÅ™Ã­zenÃ­"""
    p = pyaudio.PyAudio()
    print("\nğŸ™ï¸  DostupnÃ¡ audio zaÅ™Ã­zenÃ­:")
    print("=" * 60)

    default_input = None
    try:
        default_input = p.get_default_input_device_info()['index']
    except:
        pass

    for i in range(p.get_device_count()):
        try:
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:  # Pouze vstupnÃ­ zaÅ™Ã­zenÃ­
                marker = " [VÃCHOZÃ]" if i == default_input else ""
                print(f"ğŸ“± ID {i}: {info['name']}{marker}")
                print(f"   KanÃ¡ly: {info['maxInputChannels']}, Frekvence: {info['defaultSampleRate']} Hz")
                print("-" * 40)
        except Exception as e:
            continue

    p.terminate()
    print(f"ğŸ¯ Program pouÅ¾ije zaÅ™Ã­zenÃ­ ID: {default_input}")
    return default_input

class VoskVoiceActivityDetector:
    def __init__(self, device_id=None):
        self.device_id = device_id
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0
        self.recording_count = 0

        # KontinuÃ¡lnÃ­ zÃ¡znam pro backup
        self.continuous_frames = []
        self.continuous_recording = True
        self.backup_thread = None

        # Audio buffer pro analÃ½zu
        self.audio_buffer = deque(maxlen=int(RATE * MAX_RECORDING_TIME / CHUNK))

        # Soubor pro pÅ™episy s ÄasovÃ½mi znÃ¡mkami
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.transcript_file = os.path.join(OUTPUT_DIR, f"transcript_{timestamp}.txt")

        # Inicializace souboru s pÅ™episy
        with open(self.transcript_file, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ™ï¸ VOSK TRANSKRIPCE NAHRÃVKY - {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write("=" * 60 + "\n\n")

        # Inicializace Vosk modelu
        print(f"ğŸ§  NaÄÃ­tÃ¡m Vosk model z: {MODEL_PATH}")
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"Vosk model nenalezen v: {MODEL_PATH}")

        self.model = Model(MODEL_PATH)
        self.recognizer = KaldiRecognizer(self.model, RATE)

        # PovolenÃ­ ÄÃ¡steÄnÃ½ch vÃ½sledkÅ¯ pro real-time pÅ™epis
        self.recognizer.SetWords(True)

        print("âœ… Vosk model naÄten ÃºspÄ›Å¡nÄ›")

        # PyAudio inicializace
        self.p = pyaudio.PyAudio()

        # ZobrazenÃ­ informacÃ­ o pouÅ¾itÃ©m zaÅ™Ã­zenÃ­
        if device_id is not None:
            try:
                device_info = self.p.get_device_info_by_index(device_id)
                print(f"ğŸ¤ PouÅ¾Ã­vÃ¡m zaÅ™Ã­zenÃ­: {device_info['name']}")
            except:
                print(f"âš ï¸  ZaÅ™Ã­zenÃ­ ID {device_id} nenÃ­ dostupnÃ©, pouÅ¾Ã­vÃ¡m vÃ½chozÃ­")
                device_id = None

        self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            input_device_index=device_id,
            frames_per_buffer=CHUNK
        )

        # SpuÅ¡tÄ›nÃ­ kontinuÃ¡lnÃ­ho zÃ¡znamu
        self.start_continuous_recording()

        print("ğŸ™ï¸  VAD aktivnÃ­ - ÄekÃ¡m na Å™eÄ... (CTRL+C pro ukonÄenÃ­)")
        print(f"ğŸ“Š PrÃ¡h ticha: {SILENCE_THRESHOLD}, Min. Å™eÄ: {MIN_SPEECH_DURATION}s, Max. tichÃ¡ pauza: {SILENCE_DURATION}s")
        print(f"ğŸ’¾ PÅ™episy se uklÃ¡dajÃ­ do: {self.transcript_file}")
        print(f"ğŸ“ NahrÃ¡vky se uklÃ¡dajÃ­ do: {OUTPUT_DIR}/")

    def start_continuous_recording(self):
        """SpustÃ­ kontinuÃ¡lnÃ­ zÃ¡znam pro backup"""
        self.backup_thread = threading.Thread(target=self.continuous_backup_worker, daemon=True)
        self.backup_thread.start()

    def continuous_backup_worker(self):
        """Worker pro uklÃ¡dÃ¡nÃ­ kontinuÃ¡lnÃ­ho zÃ¡znamu"""
        backup_duration = 60  # UklÃ¡dej kaÅ¾dou minutu
        backup_counter = 0

        while self.continuous_recording:
            time.sleep(backup_duration)
            if len(self.continuous_frames) > 0:
                backup_counter += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_filename = os.path.join(OUTPUT_DIR, f"backup_part_{backup_counter:03d}_{timestamp}.wav")

                try:
                    # UloÅ¾enÃ­ backup souboru
                    with wave.open(backup_filename, 'wb') as wf:
                        wf.setnchannels(CHANNELS)
                        wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
                        wf.setframerate(RATE)
                        wf.writeframes(b''.join(self.continuous_frames))

                    print(f"ğŸ’¾ Backup uloÅ¾en: {backup_filename}")
                    self.continuous_frames = []  # VyÄisti buffer
                except Exception as e:
                    print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ backup: {e}")

    def calculate_rms(self, audio_data):
        """VÃ½poÄet RMS (Root Mean Square) pro detekci hlasitosti"""
        try:
            if not audio_data or len(audio_data) == 0:
                return 0.0

            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # Kontrola prÃ¡zdnÃ©ho pole
            if len(audio_array) == 0:
                return 0.0

            # PÅ™evod na float pro bezpeÄnÃ© vÃ½poÄty
            audio_float = audio_array.astype(np.float64)

            # VÃ½poÄet RMS s ochranou proti nevalidnÃ­m hodnotÃ¡m
            mean_square = np.mean(audio_float**2)

            # Ochrana proti zÃ¡pornÃ½m nebo NaN hodnotÃ¡m
            if mean_square <= 0 or np.isnan(mean_square) or np.isinf(mean_square):
                return 0.0

            rms = np.sqrt(mean_square)

            # FinÃ¡lnÃ­ kontrola validity
            if np.isnan(rms) or np.isinf(rms):
                return 0.0

            return float(rms)

        except Exception as e:
            print(f"âš ï¸  Chyba pÅ™i vÃ½poÄtu RMS: {e}")
            return 0.0

    def is_speech_detected(self, audio_data):
        """Detekce Å™eÄi na zÃ¡kladÄ› RMS hodnoty"""
        rms = self.calculate_rms(audio_data)

        # Debug info - mÅ¯Å¾ete zakomentovat po vyladÄ›nÃ­
        if hasattr(self, 'debug_counter'):
            self.debug_counter += 1
        else:
            self.debug_counter = 1

        # VÃ½pis RMS hodnot kaÅ¾dÃ½ch 50 chunkÅ¯ pro ladÄ›nÃ­ prahu
        if self.debug_counter % 50 == 0:
            print(f"ğŸ”Š AktuÃ¡lnÃ­ RMS: {rms:.1f} (prÃ¡h: {SILENCE_THRESHOLD})")

        return rms > SILENCE_THRESHOLD

    def save_audio_to_wav(self, frames, prefix="speech"):
        """UloÅ¾enÃ­ audio dat do WAV souboru s Äasovou znÃ¡mkou"""
        self.recording_count += 1
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(OUTPUT_DIR, f"{prefix}_{self.recording_count:03d}_{timestamp}.wav")

        try:
            wf = wave.open(filename, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            print(f"ğŸ’¾ NahrÃ¡vka uloÅ¾ena: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­: {e}")
            return None

    def save_transcript(self, text, timestamp, audio_filename, confidence=None, words_data=None):
        """UloÅ¾enÃ­ pÅ™episu do souboru s Äasovou znÃ¡mkou a detaily"""
        try:
            with open(self.transcript_file, 'a', encoding='utf-8') as f:
                f.write(f"[{timestamp}] - {audio_filename}")
                if confidence is not None:
                    f.write(f" (conf: {confidence:.2f})")
                f.write("\n")
                f.write(f"ğŸ“ {text}\n")

                # PÅ™idÃ¡nÃ­ detailÅ¯ slov pokud jsou dostupnÃ©
                if words_data:
                    word_details = []
                    for word_info in words_data:
                        word = word_info.get('word', '')
                        start = word_info.get('start', 0)
                        end = word_info.get('end', 0)
                        conf = word_info.get('conf', 0)
                        word_details.append(f"{word}[{start:.1f}-{end:.1f}s, {conf:.2f}]")

                    if word_details:
                        f.write(f"ğŸ• Detaily: {' '.join(word_details)}\n")

                f.write("-" * 60 + "\n\n")
        except Exception as e:
            print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ pÅ™episu: {e}")

    def transcribe_audio_realtime(self, audio_frames):
        """Real-time transkripce pomocÃ­ Vosk"""
        try:
            print("ğŸ§  ZpracovÃ¡vÃ¡m Å™eÄ pomocÃ­ Vosk...")

            # Reset recognizeru pro novou vÄ›tu
            self.recognizer.Reset()

            # ZpracovÃ¡nÃ­ vÅ¡ech framÅ¯ najednou
            audio_data = b''.join(audio_frames)

            # PostupnÃ© zpracovÃ¡nÃ­ po ÄÃ¡stech pro lepÅ¡Ã­ vÃ½sledky
            chunk_size = 4000  # Velikost chunku pro Vosk
            results = []
            words_data = []

            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]

                if self.recognizer.AcceptWaveform(chunk):
                    result = json.loads(self.recognizer.Result())
                    if result.get('text', '').strip():
                        results.append(result['text'].strip())

                        # SbÃ­rÃ¡nÃ­ informacÃ­ o slovech
                        if 'result' in result:
                            words_data.extend(result['result'])

            # FinÃ¡lnÃ­ vÃ½sledek
            final_result = json.loads(self.recognizer.FinalResult())
            if final_result.get('text', '').strip():
                results.append(final_result['text'].strip())
                if 'result' in final_result:
                    words_data.extend(final_result['result'])

            # SpojenÃ­ vÅ¡ech vÃ½sledkÅ¯
            full_text = ' '.join(results).strip()
            current_time = datetime.now().strftime("%H:%M:%S")

            if full_text and len(full_text) > 1:
                # VÃ½poÄet prÅ¯mÄ›rnÃ© spolehlivosti
                avg_confidence = 0
                if words_data:
                    confidences = [word.get('conf', 0) for word in words_data]
                    avg_confidence = np.mean(confidences) if confidences else 0

                print(f"ğŸ‘‚ [{current_time}] {full_text}")
                if avg_confidence > 0:
                    print(f"ğŸ“Š PrÅ¯mÄ›rnÃ¡ spolehlivost: {avg_confidence:.2f}")
                print("-" * 50)

                # UloÅ¾enÃ­ do souboru
                self.save_transcript(
                    full_text,
                    current_time,
                    f"realtime_chunk_{self.recording_count}",
                    avg_confidence,
                    words_data[:10]  # Pouze prvnÃ­ch 10 slov pro pÅ™ehlednost
                )

                return full_text
            else:
                print("ğŸ¤ Å½Ã¡dnÃ¡ srozumitelnÃ¡ Å™eÄ nebyla detekovÃ¡na")
                return None

        except Exception as e:
            print(f"âŒ Chyba pÅ™i real-time transkripci: {e}")
            return None

    def transcribe_audio_from_file(self, wav_filename):
        """Transkripce ze souboru pomocÃ­ Vosk (pro porovnÃ¡nÃ­)"""
        try:
            print(f"ğŸ§  ZpracovÃ¡vÃ¡m soubor {wav_filename} pomocÃ­ Vosk...")

            with wave.open(wav_filename, "rb") as wf:
                # Kontrola formÃ¡tu
                if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != RATE:
                    print(f"âš ï¸  NekompatibilnÃ­ formÃ¡t souboru - pÅ™evÃ¡dÃ­m...")
                    # V reÃ¡lnÃ© aplikaci byste zde mohli pÅ™idat konverzi

                # Reset recognizeru
                recognizer = KaldiRecognizer(self.model, wf.getframerate())
                recognizer.SetWords(True)

                results = []
                words_data = []

                while True:
                    data = wf.readframes(4000)
                    if len(data) == 0:
                        break

                    if recognizer.AcceptWaveform(data):
                        result = json.loads(recognizer.Result())
                        if result.get('text', '').strip():
                            results.append(result['text'].strip())
                            if 'result' in result:
                                words_data.extend(result['result'])

                # FinÃ¡lnÃ­ vÃ½sledek
                final_result = json.loads(recognizer.FinalResult())
                if final_result.get('text', '').strip():
                    results.append(final_result['text'].strip())
                    if 'result' in final_result:
                        words_data.extend(final_result['result'])

                # SpojenÃ­ vÃ½sledkÅ¯
                full_text = ' '.join(results).strip()
                current_time = datetime.now().strftime("%H:%M:%S")

                if full_text:
                    avg_confidence = 0
                    if words_data:
                        confidences = [word.get('conf', 0) for word in words_data]
                        avg_confidence = np.mean(confidences) if confidences else 0

                    print(f"ğŸ‘‚ [{current_time}] {full_text}")
                    print(f"ğŸ“Š Spolehlivost: {avg_confidence:.2f}")
                    print("-" * 50)

                    # UloÅ¾enÃ­ do souboru
                    self.save_transcript(
                        full_text,
                        current_time,
                        os.path.basename(wav_filename),
                        avg_confidence,
                        words_data
                    )

        except Exception as e:
            print(f"âŒ Chyba pÅ™i transkripci ze souboru: {e}")

    def process_audio_chunk(self, data):
        """ZpracovÃ¡nÃ­ jednoho audio chunku"""
        # PÅ™idÃ¡nÃ­ do kontinuÃ¡lnÃ­ho zÃ¡znamu
        self.continuous_frames.append(data)

        speech_detected = self.is_speech_detected(data)

        # PÅ™idÃ¡nÃ­ do bufferu pro pÅ™Ã­padnÃ© uloÅ¾enÃ­
        self.audio_buffer.append(data)

        if speech_detected:
            # DetekovÃ¡na Å™eÄ
            self.silence_counter = 0
            self.speech_counter += 1

            if not self.is_speaking:
                # ZaÄÃ¡tek Å™eÄi - kontrola minimÃ¡lnÃ­ dÃ©lky
                required_chunks = int(MIN_SPEECH_DURATION * RATE / CHUNK)
                if self.speech_counter >= required_chunks:
                    self.is_speaking = True
                    print("ğŸ—£ï¸  ZaÄÃ¡tek Å™eÄi detekovÃ¡n - nahrÃ¡vÃ¡m...")
                    # ZaÄni uklÃ¡dat audio od zaÄÃ¡tku detekovanÃ© Å™eÄi
                    buffer_start = max(0, len(self.audio_buffer) - self.speech_counter)
                    self.speech_frames = list(self.audio_buffer)[buffer_start:]

            if self.is_speaking:
                # PokraÄovÃ¡nÃ­ v nahrÃ¡vÃ¡nÃ­
                self.speech_frames.append(data)

                # Ochrana proti pÅ™Ã­liÅ¡ dlouhÃ©mu nahrÃ¡vÃ¡nÃ­
                if len(self.speech_frames) > int(MAX_RECORDING_TIME * RATE / CHUNK):
                    print("â° DosaÅ¾ena maximÃ¡lnÃ­ dÃ©lka nahrÃ¡vÃ¡nÃ­ - ukonÄujem")
                    self.finalize_speech()

        else:
            # DetekovÃ¡no ticho
            self.speech_counter = max(0, self.speech_counter - 1)  # PostupnÃ© sniÅ¾ovÃ¡nÃ­

            if self.is_speaking:
                self.silence_counter += 1
                self.speech_frames.append(data)  # ZahrÅˆ i tichÃ© ÄÃ¡sti pro kontext

                # Kontrola konce vÄ›ty
                required_silence_chunks = int(SILENCE_DURATION * RATE / CHUNK)
                if self.silence_counter >= required_silence_chunks:
                    print("ğŸ”š Konec vÄ›ty detekovÃ¡n")
                    self.finalize_speech()

    def finalize_speech(self):
        """DokonÄenÃ­ nahrÃ¡vÃ¡nÃ­ a spuÅ¡tÄ›nÃ­ transkripce"""
        if len(self.speech_frames) > 0:
            # Real-time transkripce pÅ™Ã­mo z pamÄ›ti
            transcription_thread = threading.Thread(
                target=self.transcribe_audio_realtime,
                args=(self.speech_frames.copy(),),
                daemon=True
            )
            transcription_thread.start()

            # TakÃ© uloÅ¾enÃ­ do WAV souboru pro archivaci
            wav_file = self.save_audio_to_wav(self.speech_frames, "speech")

        # Reset stavu
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0
        print("ğŸ¯ ÄŒekÃ¡m na dalÅ¡Ã­ Å™eÄ...")

    def run(self):
        """HlavnÃ­ smyÄka pro kontinuÃ¡lnÃ­ poslouchÃ¡nÃ­"""
        try:
            print("ğŸ”§ Kalibrace mikrofonu - zmÄ›Å™Ã­m ÃºroveÅˆ Å¡umu...")

            # KrÃ¡tkÃ¡ kalibrace pro zjiÅ¡tÄ›nÃ­ ÃºrovnÄ› pozadovÃ©ho Å¡umu
            noise_samples = []
            for i in range(20):  # 20 vzorkÅ¯ pro stanovenÃ­ pozadÃ­
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)
                    rms = self.calculate_rms(data)
                    if rms > 0:
                        noise_samples.append(rms)
                except:
                    continue

            if noise_samples:
                avg_noise = np.mean(noise_samples)
                suggested_threshold = max(avg_noise * 3, 300)  # 3x hlasitÄ›jÅ¡Ã­ neÅ¾ Å¡um, min. 300
                print(f"ğŸ“ˆ PrÅ¯mÄ›rnÃ½ Å¡um: {avg_noise:.1f}")
                print(f"ğŸ’¡ DoporuÄenÃ½ prÃ¡h: {suggested_threshold:.1f} (aktuÃ¡lnÃ­: {SILENCE_THRESHOLD})")
                print("ğŸ¯ Pro zmÄ›nu prahu upravte SILENCE_THRESHOLD v kÃ³du")

            print("âœ… Kalibrace dokonÄena - zaÄÃ­nÃ¡m poslouchat...")

            while True:
                # ÄŒtenÃ­ audio dat z mikrofonu
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)

                    # Kontrola validity dat pÅ™ed zpracovÃ¡nÃ­m
                    if data and len(data) == CHUNK * 2:  # 2 bytes per sample pro 16-bit
                        self.process_audio_chunk(data)
                    else:
                        print("âš ï¸  NevalidnÃ­ audio data - pÅ™eskakuji chunk")
                        continue

                except Exception as e:
                    print(f"âš ï¸  Chyba pÅ™i ÄtenÃ­ audio: {e}")
                    time.sleep(0.1)
                    continue

        except KeyboardInterrupt:
            print("\nğŸ›‘ UkonÄeno uÅ¾ivatelem.")

            # Pokud byla Å™eÄ v prÅ¯bÄ›hu, dokonÄÃ­ ji
            if self.is_speaking and len(self.speech_frames) > 0:
                print("ğŸ“ DokonÄuji posledni nahrÃ¡vÃ¡nÃ­...")
                self.finalize_speech()
                time.sleep(3)  # PoÄkej na dokonÄenÃ­ transkripce

        finally:
            self.cleanup()

    def cleanup(self):
        """VyÄiÅ¡tÄ›nÃ­ zdrojÅ¯"""
        print("ğŸ§¹ UklÃ­zÃ­m zdroje...")

        # ZastavenÃ­ kontinuÃ¡lnÃ­ho zÃ¡znamu
        self.continuous_recording = False

        # UloÅ¾enÃ­ poslednÃ­ho backup souboru
        if len(self.continuous_frames) > 0:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            final_backup = os.path.join(OUTPUT_DIR, f"final_backup_{timestamp}.wav")
            try:
                with wave.open(final_backup, 'wb') as wf:
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
                    wf.setframerate(RATE)
                    wf.writeframes(b''.join(self.continuous_frames))
                print(f"ğŸ’¾ FinÃ¡lnÃ­ backup uloÅ¾en: {final_backup}")
            except Exception as e:
                print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ finÃ¡lnÃ­ho backup: {e}")

        # DokonÄenÃ­ pÅ™episu
        try:
            with open(self.transcript_file, 'a', encoding='utf-8') as f:
                f.write(f"\nğŸ KONEC VOSK TRANSKRIPCE - {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            print(f"ğŸ“„ PÅ™epis dokonÄen a uloÅ¾en: {self.transcript_file}")
        except:
            pass

        self.stream.stop_stream()
        self.stream.close()
        self.p.terminate()

# ğŸš€ SpuÅ¡tÄ›nÃ­ programu
if __name__ == "__main__":
    print("ğŸ¤– VOSK Real-time Speech Recognition s VAD")
    print("=" * 60)

    # Kontrola existence Vosk modelu
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ CHYBA: Vosk model nenalezen!")
        print(f"ğŸ“ OÄekÃ¡vanÃ¡ cesta: {MODEL_PATH}")
        print("ğŸ’¡ StÃ¡hnÄ›te model z: https://alphacephei.com/vosk/models")
        print("ğŸ’¡ Nebo upravte MODEL_PATH v kÃ³du")
        exit(1)

    # ZobrazenÃ­ dostupnÃ½ch audio zaÅ™Ã­zenÃ­
    default_device = list_audio_devices()

    print("\n" + "="*60)
    user_input = input("ğŸ’¬ Chcete pouÅ¾Ã­t jinÃ© zaÅ™Ã­zenÃ­? Zadejte ID nebo stisknÄ›te Enter pro vÃ½chozÃ­: ")

    device_id = None
    if user_input.strip().isdigit():
        device_id = int(user_input.strip())
        print(f"âœ… Budu pouÅ¾Ã­vat zaÅ™Ã­zenÃ­ ID: {device_id}")
    else:
        print(f"âœ… Budu pouÅ¾Ã­vat vÃ½chozÃ­ zaÅ™Ã­zenÃ­")

    print("="*60)

    try:
        vad = VoskVoiceActivityDetector(device_id=device_id)
        vad.run()
    except Exception as e:
        print(f"âŒ Chyba pÅ™i spuÅ¡tÄ›nÃ­: {e}")
        print("ğŸ’¡ Zkontrolujte, zda je Vosk model sprÃ¡vnÄ› nainstalovÃ¡n a cesta je sprÃ¡vnÃ¡")