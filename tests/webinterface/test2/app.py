import ollama
import json
import pandas as pd
import logging
import os
import threading
import numpy as np
import pyaudio
from vosk import Model, KaldiRecognizer
from flask import Flask, render_template, request, redirect, url_for
from flask_socketio import SocketIO, emit
from datetime import datetime
from collections import deque
import atexit

# --- LOGGING SETUP ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
LOGS_DIR = os.path.join(BASE_DIR, 'logs')
CSV_DIR = os.path.join(BASE_DIR, 'csv_logs')

try:
    os.makedirs(LOGS_DIR, exist_ok=True)
    os.makedirs(CSV_DIR, exist_ok=True)
    print(f"Logs directory: {LOGS_DIR}")
    print(f"CSV directory: {CSV_DIR}")
except Exception as e:
    print(f"Error creating directories: {e}")
    raise

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(LOGS_DIR, 'voice_inventory.log')),
        logging.StreamHandler()
    ]
)

# --- AUDIO PARAMETERS ---
RATE = 16000
CHUNK = 1024
CHANNELS = 1
SILENCE_THRESHOLD = 150  # Lowered for better speech detection sensitivity
MIN_SPEECH_DURATION = 0.5
SILENCE_DURATION = 1.5
MAX_RECORDING_TIME = 15

# --- VOSK MODEL ---
MODEL_PATH = "/Users/jakubvavra/Documents/GitHub/Automonitoring-with-AI/tests/vosk/vosk-model-small-cs-0.4-rhasspy"

# --- FLASK AND SOCKETIO INITIALIZATION ---
app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# --- DATA ---
PREDEFINED_ITEMS = [
    'Ml√©ko', 'Chl√©b', 'M√°slo', 'S√Ωr', 'Vejce', 'Jogurt', 'Ovoce', 'Zelenina',
    'Brambory', 'Tƒõstoviny', 'R√Ω≈æe', 'Maso', 'Uzeniny', 'K√°va', 'ƒåaj', 'Cukr',
    'Mouka', 'Olej', 'Toaletn√≠ pap√≠r', 'M√Ωdlo', 'Prac√≠ prost≈ôedek', 'Rohl√≠k', 'Houska'
]

PREDEFINED_ITEMS_1 = [
    'SpO2', 'Srdeƒçn√≠ frekvence', 'Krevn√≠ tlak', 'Dechov√° frekvence', 'Teplota',
    'Bolest NRS', 'Du≈°nost', 'Kysl√≠kov√° terapie', 'L√©ky', 'Infuzn√≠ terapie',
    'Anamn√©za', 'Fyzik√°ln√≠ vy≈°et≈ôen√≠', 'P≈ô√≠znaky'
]

df_state = pd.DataFrame(
    {'Poƒç√°teƒçn√≠ stav': 0},
    index=PREDEFINED_ITEMS
)
df_state.index.name = "Polo≈æka"

# --- GLOBAL VARIABLES & LOCKS FOR THREAD SAFETY ---
speech_processor = None
is_recording = False
recording_lock = threading.Lock()  # ADDED: Lock for thread-safe access to globals

# --- LLM SYSTEM PROMPT ---
system_prompt = """
Jsi expert na extrakci dat pro syst√©m sledov√°n√≠ z√°sob. Z textu extrahuj potraviny, jejich poƒçet a typ operace.

Pravidla:
1. V√Ωstup mus√≠ b√Ωt V≈ΩDY a POUZE platn√Ω JSON objekt.
2. JSON obsahuje kl√≠ƒç 'operace', kter√Ω m≈Ø≈æe m√≠t dvƒõ hodnoty:
   - 'prirustek': Pokud text popisuje p≈ôid√°n√≠ nebo odebr√°n√≠ polo≈æek (nap≈ô. "koupil jsem", "p≈ôidal jsem", "vr√°til jsem"). Zde pou≈æij z√°porn√° ƒç√≠sla pro odebr√°n√≠.
   - 'nastaveni': Pokud text popisuje fin√°ln√≠, absolutn√≠ stav (nap≈ô. "m√°m celkem", "z≈Østalo mi", "aktu√°ln√≠ stav je").
3. Druh√Ω kl√≠ƒç je 'polozky', co≈æ je slovn√≠k, kde kl√≠ƒçe jsou n√°zvy potravin v 1. p√°du jednotn√©ho ƒç√≠sla a hodnoty jsou ƒç√≠sla.
4. Pokud text neobsahuje informace o potravin√°ch nebo operaci, vra≈• pr√°zdn√Ω slovn√≠k 'polozky' a operaci 'none'.

P≈ô√≠klady:
U≈æivatel: "Koupil jsem 2 ml√©ka a 3 rohl√≠ky"
V√Ωstup: {"operace": "prirustek", "polozky": {"ml√©ko": 2, "rohl√≠k": 3}}

U≈æivatel: "M√°m teƒè celkem 5 vajec"
V√Ωstup: {"operace": "nastaveni", "polozky": {"vejce": 5}}

U≈æivatel: "Halo"
V√Ωstup: {"operace": "none", "polozky": {}}
"""

system_prompt_1 = """

Jsi expert na extrakci l√©ka≈ôsk√Ωch dat.
Tv√Ωm √∫kolem je z textu extrahovat medic√≠nsk√© parametry, n√°lezy a stavy pacienta podle standardizovan√Ωch polo≈æek (DrABCDE, vit√°ln√≠ funkce, anamn√©za, fyzik√°ln√≠ vy≈°et≈ôen√≠, l√©ƒçba, p≈ô√≠znaky).

Pravidla:
	1.	V√Ωstup mus√≠ b√Ωt V≈ΩDY a POUZE platn√Ω JSON objekt.
	2.	JSON obsahuje dva kl√≠ƒçe:
	‚Ä¢	"operace":
	‚Ä¢	"prirustek" ‚Äì pokud text popisuje p≈ôid√°n√≠, proveden√≠ nebo zmƒõnu stavu (nap≈ô. ‚Äûnasadil jsem kysl√≠k‚Äú, ‚Äûzhor≈°ila se du≈°nost‚Äú, ‚Äûp≈ôidal jsem l√©ky‚Äú).
	‚Ä¢	"nastaveni" ‚Äì pokud text popisuje aktu√°ln√≠, fin√°ln√≠ nebo absolutn√≠ stav (nap≈ô. ‚Äûpacient m√° SpO2 98 %‚Äú, ‚Äûtepov√° frekvence je 120/min‚Äú, ‚Äûbolest 5/10‚Äú).
	‚Ä¢	"none" ‚Äì pokud text neobsahuje ≈æ√°dnou relevantn√≠ informaci o zdravotn√≠m stavu nebo intervenci.
	‚Ä¢	"polozky": slovn√≠k, kde kl√≠ƒçe jsou n√°zvy l√©ka≈ôsk√Ωch polo≈æek v 1. p√°dƒõ jednotn√©ho ƒç√≠sla (nap≈ô. ‚ÄûSpO2‚Äú, ‚Äûsrdeƒçn√≠ frekvence‚Äú, ‚Äûbolest NRS‚Äú, ‚Äûkrevn√≠ tlak‚Äú, ‚Äûdu≈°nost‚Äú) a hodnoty jsou ƒç√≠seln√© nebo textov√© √∫daje podle toho, co je ve vstupu.
	3.	Pokud text obsahuje v√≠ce r≈Øzn√Ωch √∫daj≈Ø, ulo≈æ je v≈°echny do "polozky".
	4.	Pokud nen√≠ jasn√° hodnota (nap≈ô. jen ‚Äûpacient m√° bolesti‚Äú), ulo≈æ ji jako ≈ôetƒõzec. Pokud je uvedena ƒç√≠selnƒõ (nap≈ô. ‚Äûbolest 6/10‚Äú), ulo≈æ ƒç√≠slo.
	5.	N√°zvy polo≈æek ber v≈ædy z p≈ôedem definovan√©ho seznamu (DrABCDE, anamn√©za, vy≈°et≈ôen√≠, p≈ô√≠znaky, l√©ƒçba atd. ‚Äì viz p≈ôilo≈æen√° CSV). Pokud se objev√≠ synonymum, normalizuj ho (nap≈ô. ‚Äûtep‚Äú ‚Üí ‚Äûsrdeƒçn√≠ frekvence‚Äú, ‚Äûsaturace‚Äú ‚Üí ‚ÄûSpO2‚Äú).

P≈ô√≠klady:

U≈æivatel: ‚ÄûPacient m√° SpO2 92 % a tep 120/min‚Äú
V√Ωstup: {"operace": "nastaveni", "polozky": {"SpO2": 92, "srdeƒçn√≠ frekvence": 120}}

U≈æivatel: ‚ÄûNasadil jsem kysl√≠kovou terapii a p≈ôidal infuzi‚Äú
V√Ωstup: {"operace": "prirustek", "polozky": {"oxygenoterapie": "zah√°jena", "l√©ky": "infuzn√≠ terapie"}}

U≈æivatel: ‚ÄûPacient si stƒõ≈æuje na bolesti b≈ôicha‚Äú
V√Ωstup: {"operace": "nastaveni", "polozky": {"bolest": "b≈ôicho"}}

U≈æivatel: ‚ÄûHalo‚Äú
V√Ωstup: {"operace": "none", "polozky": {}}

"""

class VoiceSpeechProcessor:
    def __init__(self):
        self.model = None
        self.recognizer = None
        self.p = None
        self.stream = None
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0
        self.audio_buffer = deque(maxlen=int(RATE * MAX_RECORDING_TIME / CHUNK))
        self.initialize_vosk()

    def initialize_vosk(self):
        try:
            if not os.path.exists(MODEL_PATH):
                raise FileNotFoundError(f"Vosk model nenalezen: {MODEL_PATH}")
            self.model = Model(MODEL_PATH)
            self.recognizer = KaldiRecognizer(self.model, RATE)
            self.recognizer.SetWords(True)
            logging.info("Vosk model √∫spƒõ≈°nƒõ naƒçten")
            print("[INFO]: Vosk model √∫spƒõ≈°nƒõ naƒçten")
        except Exception as e:
            logging.error(f"Chyba p≈ôi inicializaci Vosk: {e}")
            print(f"[CHYBA VOSK]: {e}")
            raise

    def initialize_audio(self):
        try:
            self.p = pyaudio.PyAudio()
            self.stream = self.p.open(
                format=pyaudio.paInt16,
                channels=CHANNELS,
                rate=RATE,
                input=True,
                frames_per_buffer=CHUNK,
                input_device_index=None
            )
            logging.info("Audio stream inicializov√°n")
            print("[INFO]: Audio stream inicializov√°n")
        except Exception as e:
            logging.error(f"Chyba p≈ôi inicializaci audio: {e}")
            print(f"[CHYBA AUDIO]: {e}")
            self.cleanup()
            raise

    def calculate_rms(self, audio_data):
        try:
            if not audio_data or len(audio_data) == 0:
                return 0.0
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_array) == 0:
                return 0.0
            audio_float = audio_array.astype(np.float64)
            mean_square = np.mean(audio_float**2)
            if mean_square <= 0 or np.isnan(mean_square) or np.isinf(mean_square):
                return 0.0
            rms = np.sqrt(mean_square)
            if np.isnan(rms) or np.isinf(rms):
                return 0.0
            return float(rms)
        except Exception as e:
            logging.error(f"Chyba p≈ôi v√Ωpoƒçtu RMS: {e}")
            print(f"[CHYBA RMS]: {e}")
            return 0.0

    def is_speech_detected(self, audio_data):
        rms = self.calculate_rms(audio_data)
        logging.debug(f"RMS: {rms}")
        return rms > SILENCE_THRESHOLD

    def transcribe_audio(self, audio_frames):
        try:
            if not self.recognizer:
                logging.error("Recognizer nen√≠ inicializov√°n")
                print("[CHYBA P≈òEPISU]: Recognizer nen√≠ inicializov√°n")
                return None
            if not audio_frames:
                logging.warning("≈Ω√°dn√© audio r√°mce k p≈ôepisu")
                print("[P≈òEPIS]: ≈Ω√°dn√© audio r√°mce k p≈ôepisu")
                return None

            self.recognizer.Reset()
            audio_data = b''.join(audio_frames)
            chunk_size = 4000
            results = []

            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                if self.recognizer.AcceptWaveform(chunk):
                    result = json.loads(self.recognizer.Result())
                    if result.get('text', '').strip():
                        results.append(result['text'].strip())

            final_result = json.loads(self.recognizer.FinalResult())
            if final_result.get('text', '').strip():
                results.append(final_result['text'].strip())

            full_text = ' '.join(results).strip()
            if full_text and len(full_text) > 1:
                logging.info(f"P≈ôeps√°no: {full_text}")
                print(f"[P≈òEPIS]: {full_text}")
                return full_text
            else:
                logging.warning("≈Ω√°dn√Ω p≈ôepis nenalezen")
                print("[P≈òEPIS]: ≈Ω√°dn√Ω text nerozpozn√°n")
                return None
        except Exception as e:
            logging.error(f"Chyba p≈ôi transkripci: {e}")
            print(f"[CHYBA P≈òEPISU]: {e}")
            return None

    def process_audio_chunk(self, data):
        try:
            if not self.recognizer:
                logging.error("Recognizer nen√≠ inicializov√°n p≈ôi zpracov√°n√≠ chunku")
                print("[CHYBA AUDIO]: Recognizer nen√≠ inicializov√°n")
                return

            speech_detected = self.is_speech_detected(data)
            self.audio_buffer.append(data)

            if speech_detected:
                self.silence_counter = 0
                self.speech_counter += 1

                if not self.is_speaking:
                    required_chunks = int(MIN_SPEECH_DURATION * RATE / CHUNK)
                    if self.speech_counter >= required_chunks:
                        self.is_speaking = True
                        socketio.emit('speech_start')
                        logging.info("Zaƒç√°tek ≈ôeƒçi detekov√°n")
                        print("[INFO]: Zaƒç√°tek ≈ôeƒçi detekov√°n")
                        buffer_start = max(0, len(self.audio_buffer) - self.speech_counter)
                        self.speech_frames = list(self.audio_buffer)[buffer_start:]

                if self.is_speaking:
                    self.speech_frames.append(data)

                    if len(self.speech_frames) > int(MAX_RECORDING_TIME * RATE / CHUNK):
                        logging.info("Dosa≈æena max d√©lka - ukonƒçuji")
                        print("[INFO]: Maxim√°ln√≠ d√©lka nahr√°vky dosa≈æena")
                        self.finalize_speech()

            else:
                self.speech_counter = max(0, self.speech_counter - 1)

                if self.is_speaking:
                    self.silence_counter += 1
                    self.speech_frames.append(data)

                    required_silence_chunks = int(SILENCE_DURATION * RATE / CHUNK)
                    if self.silence_counter >= required_silence_chunks:
                        logging.info("Konec vƒõty detekov√°n")
                        print("[INFO]: Konec vƒõty detekov√°n")
                        self.finalize_speech()
        except Exception as e:
            logging.error(f"Chyba p≈ôi zpracov√°n√≠ audio chunku: {e}")
            print(f"[CHYBA AUDIO]: {e}")

    def finalize_speech(self):
        try:
            if len(self.speech_frames) > 0 and self.recognizer:
                frames_to_process = self.speech_frames.copy()

                def process_transcription_and_llm():
                    try:
                        transcribed_text = self.transcribe_audio(frames_to_process)
                        if transcribed_text:
                            socketio.emit('transcription_result', {'text': transcribed_text})
                            print(f"[ODESL√ÅN P≈òEPIS]: {transcribed_text}")
                            process_with_llm(transcribed_text)
                        else:
                            socketio.emit('transcription_result', {'text': '≈Ω√°dn√Ω text nerozpozn√°n'})
                            socketio.emit('processing_error', {'message': 'Nepoda≈ôilo se rozpoznat ≈ôeƒç.'})
                            print("[ODESL√ÅN P≈òEPIS]: ≈Ω√°dn√Ω text nerozpozn√°n")
                    except Exception as e:
                        logging.error(f"NECHYCEN√Å V√ùJIMKA ve vl√°knu zpracov√°n√≠: {e}", exc_info=True)
                        print(f"[CHYBA VL√ÅKNA]: {e}")
                        socketio.emit('processing_error', {'message': f'Vnit≈ôn√≠ chyba serveru p≈ôi zpracov√°n√≠: {e}'})

                threading.Thread(target=process_transcription_and_llm, daemon=True).start()
            else:
                logging.warning("≈Ω√°dn√© r√°mce nebo recognizer nen√≠ k dispozici pro p≈ôepis")
                socketio.emit('transcription_result', {'text': '≈Ω√°dn√Ω text nerozpozn√°n'})
                socketio.emit('processing_error', {'message': 'Nebyly zaznamen√°ny ≈æ√°dn√© zvukov√© r√°mce.'})
                print("[ODESL√ÅN P≈òEPIS]: ≈Ω√°dn√Ω text nerozpozn√°n")

            self.is_speaking = False
            self.speech_frames = []
            self.silence_counter = 0
            self.speech_counter = 0
            socketio.emit('speech_end')
        except Exception as e:
            logging.error(f"Chyba p≈ôi finalizaci ≈ôeƒçi: {e}")
            print(f"[CHYBA FINALIZACE]: {e}")

    def start_listening(self):
        global is_recording
        try:
            self.initialize_audio()
            logging.info("Zahajuji nahr√°v√°n√≠")
            print("[INFO]: Zahajuji nahr√°v√°n√≠")

            while is_recording:
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)
                    if data and is_recording:
                        self.process_audio_chunk(data)
                except IOError as e:
                    logging.warning(f"Chyba I/O p≈ôi ƒçten√≠ audio (oƒçek√°v√°no p≈ôi zastaven√≠): {e}")
                    break
                except Exception as e:
                    logging.error(f"Chyba p≈ôi ƒçten√≠ audio: {e}")
                    print(f"[CHYBA ƒåTEN√ç AUDIO]: {e}")
                    continue
        except Exception as e:
            logging.error(f"Kritick√° chyba p≈ôi poslouch√°n√≠: {e}", exc_info=True)
            print(f"[CHYBA POSLOUCH√ÅN√ç]: {e}")
        finally:
            self.cleanup()
            with recording_lock:
                is_recording = False

    def stop_listening(self):
        global is_recording
        with recording_lock:
             is_recording = False

        if self.is_speaking and len(self.speech_frames) > 0 and self.recognizer:
            self.finalize_speech()

    def cleanup(self):
        try:
            if self.stream and self.stream.is_active():
                self.stream.stop_stream()
            if self.stream:
                self.stream.close()
            if self.p:
                self.p.terminate()

            self.stream = None
            self.p = None
            logging.info("Audio stream ukonƒçen")
            print("[INFO]: Audio stream ukonƒçen")
        except Exception as e:
            logging.error(f"Chyba p≈ôi ƒçi≈°tƒõn√≠ audio: {e}")
            print(f"[CHYBA ƒåI≈†TƒöN√ç]: {e}")

def save_to_csv():
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_path = os.path.join(CSV_DIR, f'inventory_{timestamp}.csv')
        df_state.to_csv(csv_path)
        logging.info(f"Tabulka ulo≈æena do CSV: {csv_path}")
        print(f"[INFO]: Tabulka ulo≈æena do CSV: {csv_path}")
    except Exception as e:
        logging.error(f"Chyba p≈ôi ukl√°d√°n√≠ CSV: {e}")
        print(f"[CHYBA CSV]: {e}")

def get_data_from_ollama(text: str) -> dict | None:
    logging.info(f"Zpracov√°v√°m LLM: {text}")
    print(f"[LLM VSTUP]: {text}")
    try:
        response = ollama.chat(
            model='gemma3:1b',
            messages=[
                {'role': 'system', 'content': system_prompt},
                {'role': 'user', 'content': text}
            ],
            options={'response_format': {'type': 'json_object'}}
        )

        json_text = response['message']['content']
        logging.info(f"LLM surov√Ω v√Ωstup: {json_text}")
        print(f"[LLM SUROV√ù V√ùSTUP]: {json_text}")
        start = json_text.find('{')
        end = json_text.rfind('}') + 1

        if start != -1 and end != -1:
            result = json.loads(json_text[start:end])
            print(f"[LLM V√ùSTUP]: {result}")
            return result
        else:
            logging.warning("LLM nevr√°til platn√Ω JSON")
            print("[CHYBA LLM]: Neplatn√Ω JSON form√°t")
            return None
    except Exception as e:
        logging.error(f"Chyba p≈ôi komunikaci s Ollama: {e}")
        print(f"[CHYBA OLLAMA]: {e}")
        return None

def process_with_llm(text: str):
    global df_state

    extracted_data = get_data_from_ollama(text)

    if extracted_data and 'operace' in extracted_data and 'polozky' in extracted_data:
        if extracted_data['operace'] != 'none' and extracted_data['polozky']:
            logging.info(f"LLM extrahovala data: {extracted_data}")
            print(f"[LLM DATA]: {extracted_data}")

            timestamp = datetime.now().strftime('%H:%M:%S')
            last_column = df_state.columns[-1]
            df_state[timestamp] = df_state[last_column].copy()

            operation = extracted_data['operace']
            items = extracted_data['polozky']

            for item_name, value in items.items():
                item_name_clean = item_name.strip().capitalize()

                if item_name_clean not in df_state.index:
                    new_row = pd.Series(0, index=df_state.columns, name=item_name_clean)
                    df_state.loc[item_name_clean] = new_row

                try:
                    numeric_value = int(value)
                    if operation == 'prirustek':
                        df_state.loc[item_name_clean, timestamp] = df_state.loc[item_name_clean, last_column] + numeric_value
                    elif operation == 'nastaveni':
                        df_state.loc[item_name_clean, timestamp] = numeric_value
                except (ValueError, TypeError):
                    logging.warning(f"Neplatn√° hodnota '{value}' pro polo≈æku '{item_name_clean}'. P≈ôeskakuji.")
                    continue

            save_to_csv()
            table_html = df_state.to_html(classes="table table-striped table-hover", border=0)
            socketio.emit('table_update', {'table': table_html, 'threat': None, 'extracted_data': extracted_data})
            print("[INFO]: Tabulka aktualizov√°na")
        else:
            logging.info("≈Ω√°dn√© polo≈æky k aktualizaci (operace: none nebo pr√°zdn√© polo≈æky)")
            socketio.emit('processing_error', {'message': 'Nerozumƒõl jsem, ≈æ√°dn√© polo≈æky k aktualizaci.'})
            print("[INFO]: ≈Ω√°dn√© polo≈æky k aktualizaci")
    else:
        logging.warning("LLM neextrahovala platn√° data")
        socketio.emit('processing_error', {'message': 'Nepoda≈ôilo se zpracovat text pomoc√≠ AI.'})
        print("[CHYBA]: LLM neextrahovala platn√° data")

# --- FLASK ROUTES ---
@app.route('/')
def index():
    table_html = df_state.to_html(classes="table table-striped table-hover", border=0)
    return render_template('voice_index_2.html', table=table_html)

@app.route('/process', methods=['POST'])
def process_text():
    user_text = request.form['text_input']
    if user_text:
        threading.Thread(target=process_with_llm, args=(user_text,)).start()
    return redirect(url_for('index'))

@app.route('/test_socket')
def test_socket():
    socketio.emit('test_event', {'message': 'SocketIO test event'})
    return "Test SocketIO event emitted. Check browser console."

# --- SOCKETIO EVENTS (FIXED FOR STABILITY) ---
@socketio.on('start_recording')
def handle_start_recording():
    global speech_processor, is_recording
    with recording_lock:
        if not is_recording:
            is_recording = True
            logging.info("Spou≈°t√≠m nahr√°v√°n√≠")
            print("[INFO]: Spou≈°t√≠m nahr√°v√°n√≠")
            speech_processor = VoiceSpeechProcessor()

            def start_listening_thread():
                try:
                    speech_processor.start_listening()
                except Exception as e:
                    logging.critical(f"NECHYCEN√Å V√ùJIMKA ve vl√°knu nahr√°v√°n√≠: {e}", exc_info=True)
                    global is_recording
                    with recording_lock:
                        is_recording = False

            threading.Thread(target=start_listening_thread, daemon=True).start()
            emit('recording_started')
        else:
            logging.warning("Pokus o spu≈°tƒõn√≠ nahr√°v√°n√≠, kter√© ji≈æ bƒõ≈æ√≠.")
            emit('recording_already_active')

@socketio.on('stop_recording')
def handle_stop_recording():
    global speech_processor, is_recording
    with recording_lock:
        if is_recording and speech_processor:
            logging.info("Zastavuji nahr√°v√°n√≠")
            print("[INFO]: Zastavuji nahr√°v√°n√≠")
            speech_processor.stop_listening()
            emit('recording_stopped')
        else:
            logging.warning("Pokus o zastaven√≠ nahr√°v√°n√≠, kter√© nen√≠ aktivn√≠.")
            emit('recording_not_active')

# Cleanup on exit
def cleanup_app():
    global speech_processor, is_recording
    logging.info("Zahajuji ƒçi≈°tƒõn√≠ aplikace p≈ôi ukonƒçen√≠...")
    if is_recording and speech_processor:
        speech_processor.stop_listening()
    logging.info("ƒåi≈°tƒõn√≠ aplikace dokonƒçeno.")
    print("[INFO]: Application cleanup completed")

atexit.register(cleanup_app)

if __name__ == '__main__':
    if not os.path.exists(MODEL_PATH):
        print(f"‚ùå CHYBA: Vosk model nenalezen na cestƒõ: {MODEL_PATH}")
        print("üí° St√°hnƒõte model z: https://alphacephei.com/vosk/models")
        exit(1)

    logging.info("Spou≈°t√≠m Voice Inventory aplikaci")
    print("[INFO]: Spou≈°t√≠m Voice Inventory aplikaci")
    socketio.run(app, debug=True, host='0.0.0.0', port=5050, allow_unsafe_werkzeug=True)