import whisper
import pyaudio
import numpy as np
import wave
import tempfile
import time
from collections import deque
import threading

# ğŸ”§ Parametry zvuku
RATE = 16000
CHUNK = 1024
CHANNELS = 1

# ğŸ”Š VAD parametry
SILENCE_THRESHOLD = 500      # PrÃ¡h pro detekci ticha (experimentujte s hodnotami 200-2000)
MIN_SPEECH_DURATION = 0.5    # MinimÃ¡lnÃ­ dÃ©lka Å™eÄi v sekundÃ¡ch pro zahÃ¡jenÃ­ nahrÃ¡vÃ¡nÃ­
SILENCE_DURATION = 1.5       # DÃ©lka ticha v sekundÃ¡ch pro ukonÄenÃ­ vÄ›ty
MAX_RECORDING_TIME = 30      # MaximÃ¡lnÃ­ dÃ©lka nahrÃ¡vÃ¡nÃ­ v sekundÃ¡ch (ochrana proti nekoneÄnÃ©mu nahrÃ¡vÃ¡nÃ­)

# ğŸ¤– Whisper model - pro ÄeÅ¡tinu doporuÄuji minimÃ¡lnÄ› "base"
model = whisper.load_model("medium")  # MÅ¯Å¾ete zvolit i "tiny", "base", "small", "large" podle potÅ™eby

class VoiceActivityDetector:
    def __init__(self):
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0

        # Audio buffer pro analÃ½zu
        self.audio_buffer = deque(maxlen=int(RATE * MAX_RECORDING_TIME / CHUNK))

        # PyAudio inicializace
        self.p = pyaudio.PyAudio()
        self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            frames_per_buffer=CHUNK
        )

        print("ğŸ™ï¸  VAD aktivnÃ­ - ÄekÃ¡m na Å™eÄ... (CTRL+C pro ukonÄenÃ­)")
        print(f"ğŸ“Š PrÃ¡h ticha: {SILENCE_THRESHOLD}, Min. Å™eÄ: {MIN_SPEECH_DURATION}s, Max. tichÃ¡ pauza: {SILENCE_DURATION}s")

    def calculate_rms(self, audio_data):
        """VÃ½poÄet RMS (Root Mean Square) pro detekci hlasitosti"""
        try:
            if not audio_data or len(audio_data) == 0:
                return 0.0

            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # Kontrola prÃ¡zdnÃ©ho pole
            if len(audio_array) == 0:
                return 0.0

            # PÅ™evod na float pro bezpeÄnÃ© vÃ½poÄty
            audio_float = audio_array.astype(np.float64)

            # VÃ½poÄet RMS s ochranou proti nevalidnÃ­m hodnotÃ¡m
            mean_square = np.mean(audio_float**2)

            # Ochrana proti zÃ¡pornÃ½m nebo NaN hodnotÃ¡m
            if mean_square <= 0 or np.isnan(mean_square) or np.isinf(mean_square):
                return 0.0

            rms = np.sqrt(mean_square)

            # FinÃ¡lnÃ­ kontrola validity
            if np.isnan(rms) or np.isinf(rms):
                return 0.0

            return float(rms)

        except Exception as e:
            print(f"âš ï¸  Chyba pÅ™i vÃ½poÄtu RMS: {e}")
            return 0.0

    def is_speech_detected(self, audio_data):
        """Detekce Å™eÄi na zÃ¡kladÄ› RMS hodnoty"""
        rms = self.calculate_rms(audio_data)

        # Debug info - mÅ¯Å¾ete zakomentovat po vyladÄ›nÃ­
        if hasattr(self, 'debug_counter'):
            self.debug_counter += 1
        else:
            self.debug_counter = 1

        # VÃ½pis RMS hodnot kaÅ¾dÃ½ch 50 chunkÅ¯ pro ladÄ›nÃ­ prahu
        if self.debug_counter % 50 == 0:
            print(f"ğŸ”Š AktuÃ¡lnÃ­ RMS: {rms:.1f} (prÃ¡h: {SILENCE_THRESHOLD})")

        return rms > SILENCE_THRESHOLD

    def save_audio_to_wav(self, frames):
        """UloÅ¾enÃ­ audio dat do doÄasnÃ©ho WAV souboru"""
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmpfile:
            wf = wave.open(tmpfile.name, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            return tmpfile.name

    def transcribe_audio(self, wav_filename):
        """Transkripce audio souboru pomocÃ­ Whisper"""
        try:
            print("ğŸ§  ZpracovÃ¡vÃ¡m Å™eÄ...")
            result = model.transcribe(
                wav_filename,
                language="cs",
                task="transcribe",
                # DodateÄnÃ© parametry pro lepÅ¡Ã­ vÃ½sledky
                temperature=0.0,  # DeterministickÃ½ vÃ½stup
                best_of=1,       # RychlejÅ¡Ã­ zpracovÃ¡nÃ­
                beam_size=1,     # RychlejÅ¡Ã­ zpracovÃ¡nÃ­
                word_timestamps=False
            )

            # VyÄiÅ¡tÄ›nÃ­ textu (odstranÄ›nÃ­ prÃ¡zdnÃ½ch vÃ½sledkÅ¯)
            text = result["text"].strip()
            if text and len(text) > 2:  # Ignoruj velmi krÃ¡tkÃ© nebo prÃ¡zdnÃ© vÃ½sledky
                print(f"ğŸ‘‚ PÅ™epis: {text}")
                print("-" * 50)
            else:
                print("ğŸ¤ Å½Ã¡dnÃ¡ srozumitelnÃ¡ Å™eÄ nebyla detekovÃ¡na")

        except Exception as e:
            print(f"âŒ Chyba pÅ™i transkripci: {e}")

    def process_audio_chunk(self, data):
        """ZpracovÃ¡nÃ­ jednoho audio chunku"""
        speech_detected = self.is_speech_detected(data)

        # PÅ™idÃ¡nÃ­ do bufferu pro pÅ™Ã­padnÃ© uloÅ¾enÃ­
        self.audio_buffer.append(data)

        if speech_detected:
            # DetekovÃ¡na Å™eÄ
            self.silence_counter = 0
            self.speech_counter += 1

            if not self.is_speaking:
                # ZaÄÃ¡tek Å™eÄi - kontrola minimÃ¡lnÃ­ dÃ©lky
                required_chunks = int(MIN_SPEECH_DURATION * RATE / CHUNK)
                if self.speech_counter >= required_chunks:
                    self.is_speaking = True
                    print("ğŸ—£ï¸  ZaÄÃ¡tek Å™eÄi detekovÃ¡n - nahrÃ¡vÃ¡m...")
                    # ZaÄni uklÃ¡dat audio od zaÄÃ¡tku detekovanÃ© Å™eÄi
                    buffer_start = max(0, len(self.audio_buffer) - self.speech_counter)
                    self.speech_frames = list(self.audio_buffer)[buffer_start:]

            if self.is_speaking:
                # PokraÄovÃ¡nÃ­ v nahrÃ¡vÃ¡nÃ­
                self.speech_frames.append(data)

                # Ochrana proti pÅ™Ã­liÅ¡ dlouhÃ©mu nahrÃ¡vÃ¡nÃ­
                if len(self.speech_frames) > int(MAX_RECORDING_TIME * RATE / CHUNK):
                    print("â° DosaÅ¾ena maximÃ¡lnÃ­ dÃ©lka nahrÃ¡vÃ¡nÃ­ - ukonÄujem")
                    self.finalize_speech()

        else:
            # DetekovÃ¡no ticho
            self.speech_counter = max(0, self.speech_counter - 1)  # PostupnÃ© sniÅ¾ovÃ¡nÃ­

            if self.is_speaking:
                self.silence_counter += 1
                self.speech_frames.append(data)  # ZahrÅˆ i tichÃ© ÄÃ¡sti pro kontext

                # Kontrola konce vÄ›ty
                required_silence_chunks = int(SILENCE_DURATION * RATE / CHUNK)
                if self.silence_counter >= required_silence_chunks:
                    print("ğŸ”š Konec vÄ›ty detekovÃ¡n")
                    self.finalize_speech()

    def finalize_speech(self):
        """DokonÄenÃ­ nahrÃ¡vÃ¡nÃ­ a spuÅ¡tÄ›nÃ­ transkripce"""
        if len(self.speech_frames) > 0:
            # UloÅ¾enÃ­ do WAV souboru
            wav_file = self.save_audio_to_wav(self.speech_frames)

            # SpuÅ¡tÄ›nÃ­ transkripce v separÃ¡tnÃ­m vlÃ¡knÄ› (neblokujÃ­cÃ­)
            transcription_thread = threading.Thread(
                target=self.transcribe_audio,
                args=(wav_file,),
                daemon=True
            )
            transcription_thread.start()

        # Reset stavu
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0
        print("ğŸ¯ ÄŒekÃ¡m na dalÅ¡Ã­ Å™eÄ...")

    def run(self):
        """HlavnÃ­ smyÄka pro kontinuÃ¡lnÃ­ poslouchÃ¡nÃ­"""
        try:
            print("ğŸ”§ Kalibrace mikrofonu - zmÄ›Å™Ã­m ÃºroveÅˆ Å¡umu...")

            # KrÃ¡tkÃ¡ kalibrace pro zjiÅ¡tÄ›nÃ­ ÃºrovnÄ› pozadovÃ©ho Å¡umu
            noise_samples = []
            for i in range(20):  # 20 vzorkÅ¯ pro stanovenÃ­ pozadÃ­
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)
                    rms = self.calculate_rms(data)
                    if rms > 0:
                        noise_samples.append(rms)
                except:
                    continue

            if noise_samples:
                avg_noise = np.mean(noise_samples)
                suggested_threshold = max(avg_noise * 3, 300)  # 3x hlasitÄ›jÅ¡Ã­ neÅ¾ Å¡um, min. 300
                print(f"ğŸ“ˆ PrÅ¯mÄ›rnÃ½ Å¡um: {avg_noise:.1f}")
                print(f"ğŸ’¡ DoporuÄenÃ½ prÃ¡h: {suggested_threshold:.1f} (aktuÃ¡lnÃ­: {SILENCE_THRESHOLD})")
                print("ğŸ¯ Pro zmÄ›nu prahu upravte SILENCE_THRESHOLD v kÃ³du")

            print("âœ… Kalibrace dokonÄena - zaÄÃ­nÃ¡m poslouchat...")

            while True:
                # ÄŒtenÃ­ audio dat z mikrofonu
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)

                    # Kontrola validity dat pÅ™ed zpracovÃ¡nÃ­m
                    if data and len(data) == CHUNK * 2:  # 2 bytes per sample pro 16-bit
                        self.process_audio_chunk(data)
                    else:
                        print("âš ï¸  NevalidnÃ­ audio data - pÅ™eskakuji chunk")
                        continue

                except Exception as e:
                    print(f"âš ï¸  Chyba pÅ™i ÄtenÃ­ audio: {e}")
                    time.sleep(0.1)
                    continue

        except KeyboardInterrupt:
            print("\nğŸ›‘ UkonÄeno uÅ¾ivatelem.")

            # Pokud byla Å™eÄ v prÅ¯bÄ›hu, dokonÄÃ­ ji
            if self.is_speaking and len(self.speech_frames) > 0:
                print("ğŸ“ DokonÄuji posledni nahrÃ¡vÃ¡nÃ­...")
                self.finalize_speech()
                time.sleep(2)  # PoÄkej na dokonÄenÃ­ transkripce

        finally:
            self.cleanup()

    def cleanup(self):
        """VyÄiÅ¡tÄ›nÃ­ zdrojÅ¯"""
        print("ğŸ§¹ UklÃ­zÃ­m zdroje...")
        self.stream.stop_stream()
        self.stream.close()
        self.p.terminate()

# ğŸš€ SpuÅ¡tÄ›nÃ­ programu
if __name__ == "__main__":
    vad = VoiceActivityDetector()
    vad.run()