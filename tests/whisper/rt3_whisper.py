import whisper
import pyaudio
import numpy as np
import wave
import tempfile
import time
import os
from collections import deque
import threading
from datetime import datetime

# ğŸ”§ Parametry zvuku
RATE = 16000
CHUNK = 1024
CHANNELS = 1

# ğŸ”Š VAD parametry
SILENCE_THRESHOLD = 200      # PrÃ¡h pro detekci ticha (experimentujte s hodnotami 200-2000)
MIN_SPEECH_DURATION = 0.5    # MinimÃ¡lnÃ­ dÃ©lka Å™eÄi v sekundÃ¡ch pro zahÃ¡jenÃ­ nahrÃ¡vÃ¡nÃ­
SILENCE_DURATION = 1.5       # DÃ©lka ticha v sekundÃ¡ch pro ukonÄenÃ­ vÄ›ty
MAX_RECORDING_TIME = 30      # MaximÃ¡lnÃ­ dÃ©lka nahrÃ¡vÃ¡nÃ­ v sekundÃ¡ch (ochrana proti nekoneÄnÃ©mu nahrÃ¡vÃ¡nÃ­)

# ğŸ“ SloÅ¾ka pro uloÅ¾enÃ­ nahrÃ¡vek a pÅ™episÅ¯
OUTPUT_DIR = "recordings"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ğŸ¤– Whisper model - pro ÄeÅ¡tinu doporuÄuji minimÃ¡lnÄ› "base"
model = whisper.load_model("base")

def list_audio_devices():
    """VypÃ­Å¡e seznam dostupnÃ½ch audio zaÅ™Ã­zenÃ­"""
    p = pyaudio.PyAudio()
    print("\nğŸ™ï¸  DostupnÃ¡ audio zaÅ™Ã­zenÃ­:")
    print("=" * 60)

    default_input = None
    try:
        default_input = p.get_default_input_device_info()['index']
    except:
        pass

    for i in range(p.get_device_count()):
        try:
            info = p.get_device_info_by_index(i)
            if info['maxInputChannels'] > 0:  # Pouze vstupnÃ­ zaÅ™Ã­zenÃ­
                marker = " [VÃCHOZÃ]" if i == default_input else ""
                print(f"ğŸ“± ID {i}: {info['name']}{marker}")
                print(f"   KanÃ¡ly: {info['maxInputChannels']}, Frekvence: {info['defaultSampleRate']} Hz")
                print("-" * 40)
        except Exception as e:
            continue

    p.terminate()
    print(f"ğŸ¯ Program pouÅ¾ije zaÅ™Ã­zenÃ­ ID: {default_input}")
    return default_input

class VoiceActivityDetector:
    def __init__(self, device_id=None):
        self.device_id = device_id
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0
        self.recording_count = 0

        # KontinuÃ¡lnÃ­ zÃ¡znam pro backup
        self.continuous_frames = []
        self.continuous_recording = True
        self.backup_thread = None

        # Audio buffer pro analÃ½zu
        self.audio_buffer = deque(maxlen=int(RATE * MAX_RECORDING_TIME / CHUNK))

        # Soubor pro pÅ™episy s ÄasovÃ½mi znÃ¡mkami
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.transcript_file = os.path.join(OUTPUT_DIR, f"transcript_{timestamp}.txt")

        # Inicializace souboru s pÅ™episy
        with open(self.transcript_file, 'w', encoding='utf-8') as f:
            f.write(f"ğŸ™ï¸ TRANSKRIPCE NAHRÃVKY - {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            f.write("=" * 60 + "\n\n")

        # PyAudio inicializace
        self.p = pyaudio.PyAudio()

        # ZobrazenÃ­ informacÃ­ o pouÅ¾itÃ©m zaÅ™Ã­zenÃ­
        if device_id is not None:
            try:
                device_info = self.p.get_device_info_by_index(device_id)
                print(f"ğŸ¤ PouÅ¾Ã­vÃ¡m zaÅ™Ã­zenÃ­: {device_info['name']}")
            except:
                print(f"âš ï¸  ZaÅ™Ã­zenÃ­ ID {device_id} nenÃ­ dostupnÃ©, pouÅ¾Ã­vÃ¡m vÃ½chozÃ­")
                device_id = None

        self.stream = self.p.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            input_device_index=device_id,
            frames_per_buffer=CHUNK
        )

        # SpuÅ¡tÄ›nÃ­ kontinuÃ¡lnÃ­ho zÃ¡znamu
        self.start_continuous_recording()

        print("ğŸ™ï¸  VAD aktivnÃ­ - ÄekÃ¡m na Å™eÄ... (CTRL+C pro ukonÄenÃ­)")
        print(f"ğŸ“Š PrÃ¡h ticha: {SILENCE_THRESHOLD}, Min. Å™eÄ: {MIN_SPEECH_DURATION}s, Max. tichÃ¡ pauza: {SILENCE_DURATION}s")
        print(f"ğŸ’¾ PÅ™episy se uklÃ¡dajÃ­ do: {self.transcript_file}")
        print(f"ğŸ“ NahrÃ¡vky se uklÃ¡dajÃ­ do: {OUTPUT_DIR}/")

    def start_continuous_recording(self):
        """SpustÃ­ kontinuÃ¡lnÃ­ zÃ¡znam pro backup"""
        self.backup_thread = threading.Thread(target=self.continuous_backup_worker, daemon=True)
        self.backup_thread.start()

    def continuous_backup_worker(self):
        """Worker pro uklÃ¡dÃ¡nÃ­ kontinuÃ¡lnÃ­ho zÃ¡znamu"""
        backup_duration = 60  # UklÃ¡dej kaÅ¾dou minutu
        backup_counter = 0

        while self.continuous_recording:
            time.sleep(backup_duration)
            if len(self.continuous_frames) > 0:
                backup_counter += 1
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_filename = os.path.join(OUTPUT_DIR, f"backup_part_{backup_counter:03d}_{timestamp}.wav")

                try:
                    # UloÅ¾enÃ­ backup souboru
                    with wave.open(backup_filename, 'wb') as wf:
                        wf.setnchannels(CHANNELS)
                        wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
                        wf.setframerate(RATE)
                        wf.writeframes(b''.join(self.continuous_frames))

                    print(f"ğŸ’¾ Backup uloÅ¾en: {backup_filename}")
                    self.continuous_frames = []  # VyÄisti buffer
                except Exception as e:
                    print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ backup: {e}")

    def calculate_rms(self, audio_data):
        """VÃ½poÄet RMS (Root Mean Square) pro detekci hlasitosti"""
        try:
            if not audio_data or len(audio_data) == 0:
                return 0.0

            audio_array = np.frombuffer(audio_data, dtype=np.int16)

            # Kontrola prÃ¡zdnÃ©ho pole
            if len(audio_array) == 0:
                return 0.0

            # PÅ™evod na float pro bezpeÄnÃ© vÃ½poÄty
            audio_float = audio_array.astype(np.float64)

            # VÃ½poÄet RMS s ochranou proti nevalidnÃ­m hodnotÃ¡m
            mean_square = np.mean(audio_float**2)

            # Ochrana proti zÃ¡pornÃ½m nebo NaN hodnotÃ¡m
            if mean_square <= 0 or np.isnan(mean_square) or np.isinf(mean_square):
                return 0.0

            rms = np.sqrt(mean_square)

            # FinÃ¡lnÃ­ kontrola validity
            if np.isnan(rms) or np.isinf(rms):
                return 0.0

            return float(rms)

        except Exception as e:
            print(f"âš ï¸  Chyba pÅ™i vÃ½poÄtu RMS: {e}")
            return 0.0

    def is_speech_detected(self, audio_data):
        """Detekce Å™eÄi na zÃ¡kladÄ› RMS hodnoty"""
        rms = self.calculate_rms(audio_data)

        # Debug info - mÅ¯Å¾ete zakomentovat po vyladÄ›nÃ­
        if hasattr(self, 'debug_counter'):
            self.debug_counter += 1
        else:
            self.debug_counter = 1

        # VÃ½pis RMS hodnot kaÅ¾dÃ½ch 50 chunkÅ¯ pro ladÄ›nÃ­ prahu
        if self.debug_counter % 50 == 0:
            print(f"ğŸ”Š AktuÃ¡lnÃ­ RMS: {rms:.1f} (prÃ¡h: {SILENCE_THRESHOLD})")

        return rms > SILENCE_THRESHOLD

    def save_audio_to_wav(self, frames, prefix="speech"):
        """UloÅ¾enÃ­ audio dat do WAV souboru s Äasovou znÃ¡mkou"""
        self.recording_count += 1
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(OUTPUT_DIR, f"{prefix}_{self.recording_count:03d}_{timestamp}.wav")

        try:
            wf = wave.open(filename, 'wb')
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
            wf.setframerate(RATE)
            wf.writeframes(b''.join(frames))
            wf.close()
            print(f"ğŸ’¾ NahrÃ¡vka uloÅ¾ena: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­: {e}")
            return None

    def save_transcript(self, text, timestamp, audio_filename):
        """UloÅ¾enÃ­ pÅ™episu do souboru s Äasovou znÃ¡mkou"""
        try:
            with open(self.transcript_file, 'a', encoding='utf-8') as f:
                f.write(f"[{timestamp}] - {audio_filename}\n")
                f.write(f"ğŸ“ {text}\n")
                f.write("-" * 60 + "\n\n")
        except Exception as e:
            print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ pÅ™episu: {e}")

    def transcribe_audio(self, wav_filename):
        """Transkripce audio souboru pomocÃ­ Whisper"""
        try:
            print("ğŸ§  ZpracovÃ¡vÃ¡m Å™eÄ...")

            # Whisper transkripce s word-level timestamps
            result = model.transcribe(
                wav_filename,
                language="cs",
                task="transcribe",
                temperature=0.0,
                best_of=1,
                beam_size=1,
                word_timestamps=True,  # PovolÃ­ ÄasovÃ© znÃ¡mky na Ãºrovni slov
                verbose=False
            )

            #result = model.transcribe(
            #    wav_filename,
            #    language="cs",
            #    fp16=False,
            #    beam_size=1,     # RychlejÅ¡Ã­
            #    best_of=1,       # RychlejÅ¡Ã­
            #    temperature=0    # DeterministickÃ½
            #)

            # VyÄiÅ¡tÄ›nÃ­ textu
            text = result["text"].strip()
            current_time = datetime.now().strftime("%H:%M:%S")

            if text and len(text) > 1:
                print(f"ğŸ‘‚ [{current_time}] {text}")
                print("-" * 50)

                # UloÅ¾enÃ­ do souboru
                self.save_transcript(text, current_time, os.path.basename(wav_filename))

                # DetailnÃ­ vÃ½pis s ÄasovÃ½mi znÃ¡mkami slov (pokud jsou dostupnÃ©)
                if "segments" in result:
                    for segment in result["segments"]:
                        if "words" in segment:
                            word_details = []
                            for word_info in segment["words"]:
                                word = word_info.get("word", "").strip()
                                start_time = word_info.get("start", 0)
                                if word:
                                    word_details.append(f"{word}[{start_time:.1f}s]")

                            if word_details:
                                detailed_text = " ".join(word_details)
                                print(f"ğŸ• DetailnÃ­ timing: {detailed_text}")

                                # UloÅ¾enÃ­ detailnÃ­ho timingu
                                with open(self.transcript_file, 'a', encoding='utf-8') as f:
                                    f.write(f"ğŸ• Timing: {detailed_text}\n\n")
            else:
                print("ğŸ¤ Å½Ã¡dnÃ¡ srozumitelnÃ¡ Å™eÄ nebyla detekovÃ¡na")

        except Exception as e:
            print(f"âŒ Chyba pÅ™i transkripci: {e}")

    def process_audio_chunk(self, data):
        """ZpracovÃ¡nÃ­ jednoho audio chunku"""
        # PÅ™idÃ¡nÃ­ do kontinuÃ¡lnÃ­ho zÃ¡znamu
        self.continuous_frames.append(data)

        speech_detected = self.is_speech_detected(data)

        # PÅ™idÃ¡nÃ­ do bufferu pro pÅ™Ã­padnÃ© uloÅ¾enÃ­
        self.audio_buffer.append(data)

        if speech_detected:
            # DetekovÃ¡na Å™eÄ
            self.silence_counter = 0
            self.speech_counter += 1

            if not self.is_speaking:
                # ZaÄÃ¡tek Å™eÄi - kontrola minimÃ¡lnÃ­ dÃ©lky
                required_chunks = int(MIN_SPEECH_DURATION * RATE / CHUNK)
                if self.speech_counter >= required_chunks:
                    self.is_speaking = True
                    print("ğŸ—£ï¸  ZaÄÃ¡tek Å™eÄi detekovÃ¡n - nahrÃ¡vÃ¡m...")
                    # ZaÄni uklÃ¡dat audio od zaÄÃ¡tku detekovanÃ© Å™eÄi
                    buffer_start = max(0, len(self.audio_buffer) - self.speech_counter)
                    self.speech_frames = list(self.audio_buffer)[buffer_start:]

            if self.is_speaking:
                # PokraÄovÃ¡nÃ­ v nahrÃ¡vÃ¡nÃ­
                self.speech_frames.append(data)

                # Ochrana proti pÅ™Ã­liÅ¡ dlouhÃ©mu nahrÃ¡vÃ¡nÃ­
                if len(self.speech_frames) > int(MAX_RECORDING_TIME * RATE / CHUNK):
                    print("â° DosaÅ¾ena maximÃ¡lnÃ­ dÃ©lka nahrÃ¡vÃ¡nÃ­ - ukonÄujem")
                    self.finalize_speech()

        else:
            # DetekovÃ¡no ticho
            self.speech_counter = max(0, self.speech_counter - 1)  # PostupnÃ© sniÅ¾ovÃ¡nÃ­

            if self.is_speaking:
                self.silence_counter += 1
                self.speech_frames.append(data)  # ZahrÅˆ i tichÃ© ÄÃ¡sti pro kontext

                # Kontrola konce vÄ›ty
                required_silence_chunks = int(SILENCE_DURATION * RATE / CHUNK)
                if self.silence_counter >= required_silence_chunks:
                    print("ğŸ”š Konec vÄ›ty detekovÃ¡n")
                    self.finalize_speech()

    def finalize_speech(self):
        """DokonÄenÃ­ nahrÃ¡vÃ¡nÃ­ a spuÅ¡tÄ›nÃ­ transkripce"""
        if len(self.speech_frames) > 0:
            # UloÅ¾enÃ­ do WAV souboru
            wav_file = self.save_audio_to_wav(self.speech_frames, "speech")

            if wav_file:
                # SpuÅ¡tÄ›nÃ­ transkripce v separÃ¡tnÃ­m vlÃ¡knÄ› (neblokujÃ­cÃ­)
                transcription_thread = threading.Thread(
                    target=self.transcribe_audio,
                    args=(wav_file,),
                    daemon=True
                )
                transcription_thread.start()

        # Reset stavu
        self.is_speaking = False
        self.speech_frames = []
        self.silence_counter = 0
        self.speech_counter = 0
        print("ğŸ¯ ÄŒekÃ¡m na dalÅ¡Ã­ Å™eÄ...")

    def run(self):
        """HlavnÃ­ smyÄka pro kontinuÃ¡lnÃ­ poslouchÃ¡nÃ­"""
        try:
            print("ğŸ”§ Kalibrace mikrofonu - zmÄ›Å™Ã­m ÃºroveÅˆ Å¡umu...")

            # KrÃ¡tkÃ¡ kalibrace pro zjiÅ¡tÄ›nÃ­ ÃºrovnÄ› pozadovÃ©ho Å¡umu
            noise_samples = []
            for i in range(20):  # 20 vzorkÅ¯ pro stanovenÃ­ pozadÃ­
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)
                    rms = self.calculate_rms(data)
                    if rms > 0:
                        noise_samples.append(rms)
                except:
                    continue

            if noise_samples:
                avg_noise = np.mean(noise_samples)
                suggested_threshold = max(avg_noise * 3, 300)  # 3x hlasitÄ›jÅ¡Ã­ neÅ¾ Å¡um, min. 300
                print(f"ğŸ“ˆ PrÅ¯mÄ›rnÃ½ Å¡um: {avg_noise:.1f}")
                print(f"ğŸ’¡ DoporuÄenÃ½ prÃ¡h: {suggested_threshold:.1f} (aktuÃ¡lnÃ­: {SILENCE_THRESHOLD})")
                print("ğŸ¯ Pro zmÄ›nu prahu upravte SILENCE_THRESHOLD v kÃ³du")

            print("âœ… Kalibrace dokonÄena - zaÄÃ­nÃ¡m poslouchat...")

            while True:
                # ÄŒtenÃ­ audio dat z mikrofonu
                try:
                    data = self.stream.read(CHUNK, exception_on_overflow=False)

                    # Kontrola validity dat pÅ™ed zpracovÃ¡nÃ­m
                    if data and len(data) == CHUNK * 2:  # 2 bytes per sample pro 16-bit
                        self.process_audio_chunk(data)
                    else:
                        print("âš ï¸  NevalidnÃ­ audio data - pÅ™eskakuji chunk")
                        continue

                except Exception as e:
                    print(f"âš ï¸  Chyba pÅ™i ÄtenÃ­ audio: {e}")
                    time.sleep(0.1)
                    continue

        except KeyboardInterrupt:
            print("\nğŸ›‘ UkonÄeno uÅ¾ivatelem.")

            # Pokud byla Å™eÄ v prÅ¯bÄ›hu, dokonÄÃ­ ji
            if self.is_speaking and len(self.speech_frames) > 0:
                print("ğŸ“ DokonÄuji posledni nahrÃ¡vÃ¡nÃ­...")
                self.finalize_speech()
                time.sleep(3)  # PoÄkej na dokonÄenÃ­ transkripce

        finally:
            self.cleanup()

    def cleanup(self):
        """VyÄiÅ¡tÄ›nÃ­ zdrojÅ¯"""
        print("ğŸ§¹ UklÃ­zÃ­m zdroje...")

        # ZastavenÃ­ kontinuÃ¡lnÃ­ho zÃ¡znamu
        self.continuous_recording = False

        # UloÅ¾enÃ­ poslednÃ­ho backup souboru
        if len(self.continuous_frames) > 0:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            final_backup = os.path.join(OUTPUT_DIR, f"final_backup_{timestamp}.wav")
            try:
                with wave.open(final_backup, 'wb') as wf:
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(self.p.get_sample_size(pyaudio.paInt16))
                    wf.setframerate(RATE)
                    wf.writeframes(b''.join(self.continuous_frames))
                print(f"ğŸ’¾ FinÃ¡lnÃ­ backup uloÅ¾en: {final_backup}")
            except Exception as e:
                print(f"âŒ Chyba pÅ™i uklÃ¡dÃ¡nÃ­ finÃ¡lnÃ­ho backup: {e}")

        # DokonÄenÃ­ pÅ™episu
        try:
            with open(self.transcript_file, 'a', encoding='utf-8') as f:
                f.write(f"\nğŸ KONEC TRANSKRIPCE - {datetime.now().strftime('%d.%m.%Y %H:%M:%S')}\n")
            print(f"ğŸ“„ PÅ™epis dokonÄen a uloÅ¾en: {self.transcript_file}")
        except:
            pass

        self.stream.stop_stream()
        self.stream.close()
        self.p.terminate()

# ğŸš€ SpuÅ¡tÄ›nÃ­ programu
if __name__ == "__main__":
    # ZobrazenÃ­ dostupnÃ½ch audio zaÅ™Ã­zenÃ­
    default_device = list_audio_devices()

    print("\n" + "="*60)
    user_input = input("ğŸ’¬ Chcete pouÅ¾Ã­t jinÃ© zaÅ™Ã­zenÃ­? Zadejte ID nebo stisknÄ›te Enter pro vÃ½chozÃ­: ")

    device_id = None
    if user_input.strip().isdigit():
        device_id = int(user_input.strip())
        print(f"âœ… Budu pouÅ¾Ã­vat zaÅ™Ã­zenÃ­ ID: {device_id}")
    else:
        print(f"âœ… Budu pouÅ¾Ã­vat vÃ½chozÃ­ zaÅ™Ã­zenÃ­")

    print("="*60)

    vad = VoiceActivityDetector(device_id=device_id)
    vad.run()